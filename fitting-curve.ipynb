{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":84175,"databundleVersionId":9816926,"sourceType":"competition"},{"sourceId":10311402,"sourceType":"datasetVersion","datasetId":6383264},{"sourceId":10347535,"sourceType":"datasetVersion","datasetId":6407492}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport pandas as pd\nimport pywt\nimport numpy as np\nimport json\n\nfrom tqdm import tqdm\n\n# Load the datasets\ngames = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2025/games.csv')\nplays = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2025/plays.csv')\nplayers = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2025/players.csv')\nplayer_play = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2025/player_play.csv')\n\n\ntracking_data_dict_play = {}\n\n# for week in tqdm(range(6, 8)):\n#     tracking_week_i = pd.read_csv(f'/kaggle/input/nfl-big-data-bowl-2025/tracking_week_{week}.csv')\n  \ntracking_data = pd.concat([\n    pd.read_csv(f'/kaggle/input/nfl-big-data-bowl-2025/tracking_week_{week}.csv') for week in tqdm(range(1, 10))\n#     pd.read_csv(f'/kaggle/input/nfl-big-data-bowl-2025/tracking_week_{week}.csv') for week in tqdm(range(1, 10))\n])\n        \n    \ndtype_dict = {'passResult':'str', 'foulName1':'str', 'foulName2': 'str'}\n\n# for (gameId, playId), group_data in tracking_data.groupby(['gameId', 'playId']):\nfor (gameId, playId), group_data in tqdm(tracking_data.groupby(['gameId', 'playId']), total=tracking_data.groupby(['gameId', 'playId']).ngroups):\n\n#     print('>',end=\"\")\n\n    if (gameId, playId) not in tracking_data_dict_play:\n        tracking_data_dict_play[(gameId, playId)] = {\n            'tracking_data': group_data,     \n            'meta_data': {\n                'gameId': gameId, 'playId': playId\n\n            }\n        }\n    else:\n        print('x',end=\"\")\n\n        tracking_data_dict_play[(gameId, playId)]['tracking_data'] = group_data\n        tracking_data_dict_play[(gameId, playId)]['meta_data'] = {'gameId': gameId, 'playId': playId                                                                         \n            }\n\n                ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:03:16.219270Z","iopub.execute_input":"2025-01-12T16:03:16.219738Z","iopub.status.idle":"2025-01-12T16:07:22.460668Z","shell.execute_reply.started":"2025-01-12T16:03:16.219701Z","shell.execute_reply":"2025-01-12T16:07:22.459697Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 9/9 [03:36<00:00, 24.06s/it]\n100%|██████████| 16124/16124 [00:14<00:00, 1150.08it/s]\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nfrom torch.optim import LBFGS\n\nimport numpy as np\n\n# def calculate_eccentricity(A, B, C):\ndef calculate_eccentricity(A, B, C, s, acc, dis, o, dir_, theta_) :\n    # Step 1: Calculate eigenvalues for semi-major and semi-minor axis lengths\n    eig_val1 = 0.5 * (A + C + np.sqrt((A - C)**2 + B**2))\n    eig_val2 = 0.5 * (A + C - np.sqrt((A - C)**2 + B**2))\n    a = np.sqrt(1 / np.abs(eig_val1))  # Major axis length\n    b = np.sqrt(1 / np.abs(eig_val2))  # Minor axis length\n#     a, b = sorted([a, b], reverse=True)  # Ensure a >= b\n    \n#     theta_deg = torch.degrees(theta_)\n    theta_deg = torch.rad2deg(theta_)\n\n \n    if torch.isclose((theta_deg % 180), torch.tensor(0.0, device=theta_deg.device), atol=5.0):\n        orientation = \"horizontal\"\n        eccentricity = a**2/b**2\n#     elif np.isclose(theta_deg % 180, 90, atol=5):  # e.g., 85° to 95°\n    elif torch.isclose((theta_deg % 180), torch.tensor(90.0, device=theta_deg.device), atol=5.0):\n        orientation = \"vertical\"\n        eccentricity = b**2/a**2\n    else:\n        orientation = \"diagonal\"  # if not close to 0° or 90°\n        eccentricity = b**2/a**2\n#         eccentricity = a**2/b**2\n        \n    return eccentricity#, is_horizontal, theta\n\n\n\n\n# Objective function to minimize\ndef objective_fn(params, x, y):\n    return torch.sum(conics(params, x, y)**2)\n\n\n\n\n\n\n# def closure():\ndef closure(optimiser, sx ,sy, params ):\n    optimizer.zero_grad()\n    # Split params into sx and sy (assuming sx and sy are of the same size)\n#     sx = params[:len(sx)]  # First part of params for sx\n#     sy = params[len(sx):]  # Second part of params for sy\n\n    # Now call the objective function with sx and sy\n    loss = objective_fn(params, sx, sy)\n    loss.backward()\n    return loss\n\n\n\n# Define conic equation\ndef conics(params, x, y):\n    a, b, c, d, e, f = params\n    return a * x**2 + b * x * y + c * y**2 + d * x + e * y + f\n\n# # Objective function to minimize\n# def objective_fn(params, x, y):\n#     return np.sum(conics(params, x, y)**2)\n\ndef curvature_conic(A, B, C, D, E, x, y):\n    # First derivative (dy/dx)\n    numerator_first = -2*A*x - D\n    denominator_first = B*x + 2*C*y + E\n    dy_dx = numerator_first / denominator_first\n    \n    # Second derivative (d^2y/dx^2)\n    # Derivatives of the numerator and denominator\n    d_numerator_first_dx = -2*A\n    d_denominator_first_dx = B\n    \n    # Using the quotient rule for the second derivative\n    numerator_second = (d_numerator_first_dx * denominator_first) - (numerator_first * d_denominator_first_dx)\n    denominator_second = denominator_first**2\n    \n    d2y_dx2 = numerator_second / denominator_second\n\n    # Curvature calculation\n    curvature = d2y_dx2 / (1 + dy_dx**2)**(3/2)\n    \n    return curvature\n\n# def average_curvature(A, B, C, D, E, x_start, x_end, num_points=100):\n#     x_values = np.linspace(x_start, x_end, num_points)\n#     curvature_values = []\n    \n#     for x in x_values:\n#         # To find corresponding y values, we would typically need to solve the conic equation.\n#         # For simplicity, we can use a fixed value of y for average calculation, but this may not be accurate.\n#         # Here, just for demonstration, we are considering y = 0, which might not always lie on the conic.\n#         y = 0  \n#         curv = curvature_conic(A, B, C, D, E, x, y)\n#         curvature_values.append(curv)\n\n#     # Calculate average curvature\n#     average_curv = np.mean(curvature_values)\n#     return average_curv\n\ndef average_curvature(A, B, C, D, E, x_start, x_end, num_points=100):\n    # Create a tensor of x values, using torch.linspace\n    x_values = torch.linspace(x_start, x_end, num_points, device='cuda' if torch.cuda.is_available() else 'cpu')\n    \n    # Initialize the curvature_values tensor\n    curvature_values = torch.zeros_like(x_values)\n    \n    # Compute the curvature for each x value\n    for i, x in enumerate(x_values):\n        y = 0  # Fixed y value for the calculation (this can be modified based on specific requirements)\n        curvature_values[i] = curvature_conic(A, B, C, D, E, x, y)\n    \n    # Calculate the average curvature using torch.mean\n    average_curv = torch.mean(curvature_values)\n    \n    return average_curv\n\n\n\n\n\n\n# #hyperbolic only\n# def calculate_eccentricity(A, B, C, s, acc, dis, o, dir_) :\ndef calculate_eccentricity_fx(A, B, C, s, acc, dis, o, dir_, theta_) :\n    eig_val1 = 0.5 * (A + C + np.sqrt((A - C)**2 + B**2))\n    eig_val2 = 0.5 * (A + C - np.sqrt((A - C)**2 + B**2))\n    a = np.sqrt(1 / np.abs(eig_val1))\n    b = np.sqrt(1 / np.abs(eig_val2))\n#     a, b = sorted([a, b], key=abs)\n#     a, b = sorted([a, b], key=abs, reverse=True)\n#     a, b = sorted([a, b])\n    a, b = sorted([a, b], reverse=True)\n    \n#         eccentricity = np.sqrt(1 - (b**2 / a**2))\n#     eccentricity = np.sqrt(1 + (b**2 / a**2))\n#     return np.sqrt(1 + (b**2 / a**2)) #\n#     return (b**2 / a**2)\n#     return np.log(b**2 / a**2)\n#     return (a / b) #asect ratio\n    return (a**2/b**2) # not ^\n#     return 2*b**2/a  #latus rectum lr\n#     return np.abs(theta_)\n#     return B**2 - 4 * A * C #dis\n#     return (b**2 / a**2) #asect ratio\n#     return np.sqrt((b**2 / a**2))\n#else return np.nan","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:07:22.462325Z","iopub.execute_input":"2025-01-12T16:07:22.462687Z","iopub.status.idle":"2025-01-12T16:07:25.063447Z","shell.execute_reply.started":"2025-01-12T16:07:22.462655Z","shell.execute_reply":"2025-01-12T16:07:25.062573Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# def calculate_conic_eccentricity(A, B, C):\n#     discriminant = B**2 - 4*A*C\n#     # D = B**2 - 4*A*C #discriminant\n\n    \n#     if discriminant < 0:\n#         # Ellipse or Circle\n#         eig_val1 = 0.5 * (A + C + np.sqrt((A - C)**2 + B**2))\n#         eig_val2 = 0.5 * (A + C - np.sqrt((A - C)**2 + B**2))\n#         a = np.sqrt(1 / np.abs(eig_val1))\n#         b = np.sqrt(1 / np.abs(eig_val2))\n#         eccentricity = np.sqrt(1 - (b**2 / a**2))\n#         conic_type = \"Ellipse\" if a != b else \"Circle\"\n#     elif discriminant == 0:\n#         eccentricity = 1\n#         conic_type = \"Parabola\"\n#     else:\n#         # Hyperbola\n#         eig_val1 = 0.5 * (A + C + np.sqrt((A - C)**2 + B**2))\n#         eig_val2 = 0.5 * (A + C - np.sqrt((A - C)**2 + B**2))\n#         a = np.sqrt(1 / np.abs(eig_val1))\n#         b = np.sqrt(1 / np.abs(eig_val2))\n#         eccentricity = np.sqrt(1 + (b**2 / a**2))\n#         conic_type = \"Hyperbola\"\n    \n#     return {\"conic_type\": conic_type, \"eccentricity\": eccentricity}\n\n\n# def calculate_conic_eccentricity(A, B, C):\n#     discriminant = B**2 - 4*A*C\n#     # D = B**2 - 4*A*C #discriminant\n#     eig_val1 = 0.5 * (A + C + np.sqrt((A - C)**2 + B**2))\n#     eig_val2 = 0.5 * (A + C - np.sqrt((A - C)**2 + B**2))\n#     a = np.sqrt(1 / np.abs(eig_val1))\n#     b = np.sqrt(1 / np.abs(eig_val2))\n\n#     if a > b:  # Ensure a is the semi-major axis\n#         al = a\n#     else:  # Handle edge cases where axes may be swapped\n#         bl = b\n    \n#     if discriminant < 0:\n#         # Ellipse or Circle\n\n#         eccentricity = np.sqrt(1 - (bl**2 / al**2))\n#         conic_type = \"Ellipse\" if a != b else \"Circle\"\n#     elif discriminant == 0:\n#         eccentricity = 1\n#         conic_type = \"Parabola\"\n#     else:\n#         # Hyperbola\n\n#         eccentricity = np.sqrt(1 + (bl**2 / al**2))\n#         conic_type = \"Hyperbola\"\n    \n#     # return {\"conic_type\": conic_type, \"eccentricity\": eccentricity}\n    # return eccentricity\n\n\n\n\ndef calculate_conic_eccentricity_extended(A, B, C, D, E, F):\n\n    # discriminant\n    discriminant = B**2 - 4*A*C\n    # D = B**2 - 4*A*C #discriminant\n\n    # determinant\n    determinant = np.linalg.det([[A, B/2, D/2], \n                                 [B/2, C, E/2], \n                                 [D/2, E/2, F]])\n    # determinant = np.linalg.det([[A, B/2, D/2], \n    #                              [B/2, C, E/2], \n\n    # # Check for degenerate conics\n    # if determinant == 0:\n    #     if discriminant < 0:\n    #         conic_type = \"Degenerate Ellipse (Point)\"\n    #     elif discriminant == 0:\n    #         conic_type = \"Degenerate Parabola (Parallel Lines)\"\n    #     elif discriminant > 0:\n    #         conic_type = \"Degenerate Hyperbola (Intersecting Lines)\"\n    #     # return {\"conic_type\": conic_type, \"eccentricity\": None}\n    #     # return eccentricity\n    #     return -1\n\n\n                                                                             \n    # axes lengths\n    eig_val1 = 0.5 * (A + C + np.sqrt((A - C)**2 + B**2))\n    eig_val2 = 0.5 * (A + C - np.sqrt((A - C)**2 + B**2))\n    a = np.sqrt(1 / np.abs(eig_val1))\n    b = np.sqrt(1 / np.abs(eig_val2))\n    if a > b:  # Ensure a is the semi-major axis\n        al = a\n        bl = b\n    else:  # Handle edge cases where axes may be swapped\n        bl = a\n        al = b\n\n\n\n    \n    if discriminant < 0:\n        # Ellipse or Circle\n\n        eccentricity = np.sqrt(1 - (bl**2 / al**2))\n        conic_type = \"Ellipse\" if a != b else \"Circle\"\n    elif discriminant == 0:\n        eccentricity = 1\n        conic_type = \"Parabola\"\n    else:\n        # Hyperbola\n\n        eccentricity = np.sqrt(1 + (bl**2 / al**2))\n        conic_type = \"Hyperbola\"\n    \n    # return {\"conic_type\": conic_type, \"eccentricity\": eccentricity}\n    # return eccentricity\n    # return (eccentricity, determinant, discriminant, conic_type)\n    return eccentricity","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:07:30.060765Z","iopub.execute_input":"2025-01-12T16:07:30.061260Z","iopub.status.idle":"2025-01-12T16:07:30.070070Z","shell.execute_reply.started":"2025-01-12T16:07:30.061230Z","shell.execute_reply":"2025-01-12T16:07:30.068905Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import pandas as pd\n\ngames = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2025/games.csv')\nplays = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2025/plays.csv')\nplayers = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2025/players.csv')\nplayer_play = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2025/player_play.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:07:41.642675Z","iopub.execute_input":"2025-01-12T16:07:41.643043Z","iopub.status.idle":"2025-01-12T16:07:43.553078Z","shell.execute_reply.started":"2025-01-12T16:07:41.643015Z","shell.execute_reply":"2025-01-12T16:07:43.551958Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# params = p0.clone().detach().requires_grad_(True).to(device)\n# params","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:08:07.280444Z","iopub.execute_input":"2025-01-12T16:08:07.280963Z","iopub.status.idle":"2025-01-12T16:08:07.285220Z","shell.execute_reply.started":"2025-01-12T16:08:07.280919Z","shell.execute_reply":"2025-01-12T16:08:07.283891Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import torch\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:08:11.612009Z","iopub.execute_input":"2025-01-12T16:08:11.612364Z","iopub.status.idle":"2025-01-12T16:08:11.618653Z","shell.execute_reply.started":"2025-01-12T16:08:11.612335Z","shell.execute_reply":"2025-01-12T16:08:11.617775Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"device(type='cpu')"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nfrom scipy.optimize import minimize\n\n\n# # Objective function to minimize\n# def objective_fn(params, x, y):\n#     return np.sum(conics(params, x, y)**2)\n\n# Objective function to minimize\ndef objective_fn(params, x, y):\n    return torch.sum(conics(params, x, y)**2)\n\n\nimport torch\nfrom torch.optim import LBFGS\n\n# # Define the closure function for optimization\n# def closure():\n#     optimizer.zero_grad()  # Clear previous gradients\n#     loss = objective_fn(params, sx, sy)  # Compute loss using objective_fn\n#     loss.backward()  # Backpropagate the gradients\n#     return loss\n\n\n# def closure():\ndef closure(optimiser, sx ,sy, params ):\n    optimizer.zero_grad()\n    # Split params into sx and sy (assuming sx and sy are of the same size)\n#     sx = params[:len(sx)]  # First part of params for sx\n#     sy = params[len(sx):]  # Second part of params for sy\n\n    # Now call the objective function with sx and sy\n    loss = objective_fn(params, sx, sy)\n    loss.backward()\n    return loss\n\n\n\n# Define conic equation\ndef conics(params, x, y):\n    a, b, c, d, e, f = params\n    return a * x**2 + b * x * y + c * y**2 + d * x + e * y + f\n\n# # Objective function to minimize\n# def objective_fn(params, x, y):\n#     return np.sum(conics(params, x, y)**2)\n\ndef curvature_conic(A, B, C, D, E, x, y):\n    # First derivative (dy/dx)\n    numerator_first = -2*A*x - D\n    denominator_first = B*x + 2*C*y + E\n    dy_dx = numerator_first / denominator_first\n    \n    # Second derivative (d^2y/dx^2)\n    # Derivatives of the numerator and denominator\n    d_numerator_first_dx = -2*A\n    d_denominator_first_dx = B\n    \n    # Using the quotient rule for the second derivative\n    numerator_second = (d_numerator_first_dx * denominator_first) - (numerator_first * d_denominator_first_dx)\n    denominator_second = denominator_first**2\n    \n    d2y_dx2 = numerator_second / denominator_second\n\n    # Curvature calculation\n    curvature = d2y_dx2 / (1 + dy_dx**2)**(3/2)\n    \n    return curvature\n\n# def average_curvature(A, B, C, D, E, x_start, x_end, num_points=100):\n#     x_values = np.linspace(x_start, x_end, num_points)\n#     curvature_values = []\n    \n#     for x in x_values:\n#         # To find corresponding y values, we would typically need to solve the conic equation.\n#         # For simplicity, we can use a fixed value of y for average calculation, but this may not be accurate.\n#         # Here, just for demonstration, we are considering y = 0, which might not always lie on the conic.\n#         y = 0  \n#         curv = curvature_conic(A, B, C, D, E, x, y)\n#         curvature_values.append(curv)\n\n#     # Calculate average curvature\n#     average_curv = np.mean(curvature_values)\n#     return average_curv\n\ndef average_curvature(A, B, C, D, E, x_start, x_end, num_points=100):\n    # Create a tensor of x values, using torch.linspace\n    x_values = torch.linspace(x_start, x_end, num_points, device='cuda' if torch.cuda.is_available() else 'cpu')\n    \n    # Initialize the curvature_values tensor\n    curvature_values = torch.zeros_like(x_values)\n    \n    # Compute the curvature for each x value\n    for i, x in enumerate(x_values):\n        y = 0  # Fixed y value for the calculation (this can be modified based on specific requirements)\n        curvature_values[i] = curvature_conic(A, B, C, D, E, x, y)\n    \n    # Calculate the average curvature using torch.mean\n    average_curv = torch.mean(curvature_values)\n    \n    return average_curv\n\n\n\n\n\n\n# #hyperbolic only\n# def calculate_eccentricity(A, B, C, s, acc, dis, o, dir_) :\ndef calculate_eccentricity_fx(A, B, C, s, acc, dis, o, dir_, theta_) :\n    eig_val1 = 0.5 * (A + C + np.sqrt((A - C)**2 + B**2))\n    eig_val2 = 0.5 * (A + C - np.sqrt((A - C)**2 + B**2))\n    a = np.sqrt(1 / np.abs(eig_val1))\n    b = np.sqrt(1 / np.abs(eig_val2))\n#     a, b = sorted([a, b], key=abs)\n#     a, b = sorted([a, b], key=abs, reverse=True)\n#     a, b = sorted([a, b])\n    a, b = sorted([a, b], reverse=True)\n    \n#         eccentricity = np.sqrt(1 - (b**2 / a**2))\n#     eccentricity = np.sqrt(1 + (b**2 / a**2))\n#     return np.sqrt(1 + (b**2 / a**2)) #\n#     return (b**2 / a**2)\n#     return np.log(b**2 / a**2)\n#     return (a / b) #asect ratio\n    return (a**2/b**2) # not ^\n#     return 2*b**2/a  #latus rectum lr\n#     return np.abs(theta_)\n#     return B**2 - 4 * A * C #dis\n#     return (b**2 / a**2) #asect ratio\n#     return np.sqrt((b**2 / a**2))\n#else return np.nan\n\n\n\n# Initial guess for the conic parameters\n# p0 = [1, 1, 1, 1, 1, 1]\np0 = torch.tensor([1, 1, 1, 1, 1, 1], dtype=torch.float32, requires_grad=True, device=device)\n\n\n# Initialize the main dictionary to store no transforms\nno_transforms = {}\n\n# Summary stats for tracking processing\nplay_count_with_snap_event = 0\nplay_count_without_snap_event = 0\nevents_without_snap = {}\n\nn = 500 #50 #500  # Subset for testing\n# tracking_data_dict_play_subset = dict(list(tracking_data_dict_play.items())[:n])\ntracking_data_dict_play_subset = dict(list(tracking_data_dict_play.items()))\n\n\n# Device setup: Use GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\nfor (gameId, playId), group_data in tqdm(tracking_data_dict_play_subset.items()) :\n\n    # Initialize gameId in no_transforms if not already present\n    if gameId not in no_transforms:\n        no_transforms[gameId] = {}\n\n    # Initialize playId within the gameId if not already present\n    if playId not in no_transforms[gameId]:\n        no_transforms[gameId][playId] = {\n            'offense': {},\n            'defense': {},\n        }\n\n    \n    offensiveTeamAbbr = plays[(plays['gameId'] == gameId) & (plays['playId'] == playId)].iloc[0]['possessionTeam']\n    defensiveTeamAbbr = plays[(plays['gameId'] == gameId) & (plays['playId'] == playId)].iloc[0]['defensiveTeam']\n\n    # Retrieve tracking data for the current game/play\n    tracking_data = group_data['tracking_data']\n    \n\n    # Process tracking data for each player (nflId)\n    for nflId, player_data in tracking_data.groupby('nflId'):\n        if pd.isna(nflId):  # Skip if it's NaN (ball)\n            continue\n\n        ball_snap_idx = player_data[player_data['event'] == 'ball_snap'].index.min()\n        snap_direct_idx = player_data[player_data['event'] == 'snap_direct'].index.min()\n\n        snap_event_idx = min(ball_snap_idx, snap_direct_idx) if pd.notna(snap_direct_idx) and pd.notna(ball_snap_idx) else (ball_snap_idx if pd.notna(ball_snap_idx) else snap_direct_idx)\n\n        \n        \n#         # Assuming player_data is sorted by time, so that the last row represents the latest event\n#         last_event_idx = player_data.groupby('player_id')['event'].idxmax()  # Adjust to get the last event by time\n#         last_event = player_data.loc[last_event_idx]\n\n\n\n        if pd.notna(snap_event_idx):\n            player_data_truncated = player_data.loc[:snap_event_idx]\n            play_count_with_snap_event += 1\n#         else : \n#             print(\"No\")\n#             player_data_truncated = None\n            \n\n            \n            \n            \n\n#             x_ = player_data_truncated['x'].values\n            x_ = torch.tensor(player_data_truncated['x'].values, device=device)\n            y_ = torch.tensor(player_data_truncated['y'].values, device=device)\n            s_ = torch.tensor(player_data_truncated['s'].values, device=device)\n            a_ = torch.tensor(player_data_truncated['a'].values, device=device)\n            dis_ = torch.tensor(player_data_truncated['dis'].values, device=device)\n            dir_ = torch.tensor(player_data_truncated['dir'].values, device=device)\n            \n            o_ = torch.tensor(player_data_truncated['o'].values, device=device)\n\n            #\n# #             disp = np.sum(dis_) #$disall = np.sum(dis_)\n#             disp = player_data_truncated['dis'].sum()  # Instead of np.sum\n#             xl = x_[-1]\n#             yl = y_[-1]\n# #             x_mean = np.mean(x_)\n# #             y_mean = np.mean(y_)\n#             x_mean = player_data_truncated['x'].mean()\n#             y_mean = player_data_truncated['y'].mean()\n        \n#             # Sum of 'dis' (already in CUDA if player_data_truncated['dis'] is transferred as tensor)\n#             disp = dis_.sum()  # PyTorch automatically performs the sum on GPU\n\n            #\n#             # Last elements of x_ and y_ (directly available in GPU tensors)\n#             xl = x_[-1]\n#             yl = y_[-1]\n\n#             # Mean calculations using PyTorch\n#             x_mean = x_.mean()  # Mean calculated on GPU\n#             y_mean = y_.mean()\n\n            #\n            #optimized version\n            disp = dis_.sum()  # Sum of 'dis' directly on GPU\n            xl = x_[-1]        # Last x-coordinate\n            yl = y_[-1]        # Last y-coordinate\n            x_mean = x_.mean() # Mean of x-coordinates on GPU\n            y_mean = y_.mean() # Mean of y-coordinates on GPU\n\n\n\n            #\n#             dir_rad = np.radians(dir_)\n#             sx = s_*np.sin(dir_rad) #np.mean(s_*np.sin()  \n#             sy = s_*np.cos(dir_rad)\n#             ax = a_*np.sin(dir_rad)\n#             ay = a_*np.cos(dir_rad)\n#             param_s = minimize(objective_fn, p0, args=(sx, sy), method='L-BFGS-B') #xs\n#             param_a = minimize(objective_fn, p0, args=(sy, ay), method='L-BFGS-B')\n#             sa,sb,sc,sd,se,sf = param_s.x #$params_s.\n#             aa,ab,ac,ad,ae,af = param_a.x\n#             theta_s = np.arctan2(sb,sa-sc)/2\n#             theta_a = np.arctan2(ab,aa-ac)/2\n            \n#             # Convert dir_ to radians\n#             dir_rad = torch.radians(dir_)\n\n#             # Trigonometric operations (PyTorch versions)\n#             sx = s_ * torch.sin(dir_rad)  # PyTorch handles this on GPU\n#             sy = s_ * torch.cos(dir_rad)\n#             ax = a_ * torch.sin(dir_rad)\n#             ay = a_ * torch.cos(dir_rad)\n#             param_s = minimize(objective_fn, p0, args=(sx.cpu().numpy(), sy.cpu().numpy()), method='L-BFGS-B')\n#             param_a = minimize(objective_fn, p0, args=(sy.cpu().numpy(), ay.cpu().numpy()), method='L-BFGS-B')\n\n#             # Extract parameters\n#             sa, sb, sc, sd, se, sf = param_s.x\n#             aa, ab, ac, ad, ae, af = param_a.x\n\n#             # Trigonometric calculations\n#             theta_s = torch.arctan2(torch.tensor(sb), torch.tensor(sa - sc)) / 2\n#             theta_a = torch.arctan2(torch.tensor(ab), torch.tensor(aa - ac)) / 2\n \n\n\n            dir_rad = torch.deg2rad(dir_) #not radians\n            sx = s_ * torch.sin(dir_rad)  # PyTorch handles this on GPU\n            sy = s_ * torch.cos(dir_rad)\n            ax = a_ * torch.sin(dir_rad)\n            ay = a_ * torch.cos(dir_rad)\n            \n            # Define initial parameters for optimization\n#             params = torch.tensor(p0, requires_grad=True, device=device)\n            params = p0.clone().detach().requires_grad_(True).to(device)\n\n            \n            # Create LBFGS optimizer\n            optimizer = LBFGS([params])\n            \n#             # Step through the optimizer\n#             optimizer.step(closure)\n            \n            # Use closure for (sx, sy)\n            optimizer.step(lambda: closure(optimizer, sx, sy, params))\n#             optimizer.step(lambda: closure(optimizer, sx, sy))\n\n            # After optimization, the parameters are updated. You can now access the optimized values:\n            optimized_params = params.detach()  # Detach the tensor from the computation graph\n            \n            # Extract the optimized parameters (sa, sb, sc, sd, se, sf) for further use\n            sa, sb, sc, sd, se, sf = optimized_params.tolist()  # Convert tensor to list for easy usage\n\n            # Perform any further calculations or use these parameters in your code\n#             theta_s = torch.arctan2(sb, sa - sc) / 2\n            theta_s = torch.arctan2(torch.tensor(sb, device=device), torch.tensor(sa - sc, device=device)) / 2\n\n            \n            \n            \n#             params = torch.tensor(p0, requires_grad=True, device=device)\n            params = p0.clone().detach().requires_grad_(True).to(device)\n            optimizer = LBFGS([params])\n            optimizer.step(lambda: closure(optimizer, ax, ay, params))\n            optimized_params = params.detach()\n            aa, ab, ac, ad, ae, af = optimized_params.tolist()\n#             theta_a = torch.arctan2(ab, aa - ac) / 2\n            theta_a = torch.arctan2(torch.tensor(ab, device=device), torch.tensor(aa - ac, device=device)) / 2\n\n            \n            \n            \n#             params = torch.tensor(p0, requires_grad=True, device=device)\n            params = p0.clone().detach().requires_grad_(True).to(device)\n            optimizer = LBFGS([params])\n            optimizer.step(lambda: closure(optimizer, x_, y_, params))   # xx or xa\n            optimized_params = params.detach()\n            a,b,c,d,e,f = optimized_params.tolist() # aa bb cc ..\n#             theta_ = torch.arctan2(ab, aa - ac) / 2\n            theta_ = torch.arctan2(torch.tensor(b, device=device), torch.tensor(a - c, device=device)) / 2\n            cos_theta_, sin_theta_ = torch.cos(theta_), torch.sin(theta_)\n\n            \n            \n            \n#             params = minimize(objective_fn, p0, args=(x_, y_), method='L-BFGS-B')\n#             a,b,c,d,e,f = params.x\n        \n#             theta_ = np.arctan2(b,a-c)/2\n#             cos_theta_, sin_theta_ = np.cos(theta_), np.sin(theta_)\n\n#             a_prime = a*cos_theta_**2 +  b*cos_theta_*sin_theta_ +  c*sin_theta_**2\n#             b_prime = 2*(c-a)*cos_theta_*sin_theta_ + b*(cos_theta_**2 -sin_theta_**2)\n#             c_prime = a*sin_theta_**2 - b*cos_theta_*sin_theta_ + c*cos_theta_**2\n\n            \n#             params = torch.tensor(p0, requires_grad=True, device=device)\n#             optimizer = LBFGS([params])\n#             optimizer.step(closure)\n#             optimized_params = params.detach() \n#             sa, sb, sc, sd, se, sf = optimized_params.tolist()\n#             theta_s = torch.arctan2(sb, sa - sc) / 2\n#             theta_a = torch.arctan2(ab, aa - ac) / 2\n            \n            \n#             eccentricity = calculate_eccentricity(a, b, c, np.mean(s_), np.mean(a_), np.mean(dis_), np.mean(o_), np.mean(dir_), theta_)\n#             eccentricity = calculate_eccentricity(a, b, c, torch.mean(s_), torch.mean(a_), torch.mean(dis_), torch.mean(o_), torch.mean(dir_), theta_)\n\n#             curvature = curvature_conic(a,b,c,d,e, np.mean(x_), np.mean(y_) )\n#             curvature = curvature_conic(a, b, c, d, e, torch.mean(x_), torch.mean(y_))\n\n#             avg_cuvx = average_curvature(a,b,c,d,e, x_[0], x_[-1] )\n#             avg_cuvy = average_curvature(a,b,c,d,e, y_[0], y_[-1] )\n#             discriminant = b**2 - 4 * a * c\n            \n#             eig_val1 = 0.5 * (a + c + np.sqrt((a - c)**2 + b**2))\n#             eig_val2 = 0.5 * (a + c - np.sqrt((a - c)**2 + b**2))\n#             al = np.sqrt(1 / np.abs(eig_val1))\n#             bl = np.sqrt(1 / np.abs(eig_val2))\n#             al, bl = sorted([al, bl], reverse=True)\n\n    \n\n#             arxy = calculate_eccentricity_fx(a, b, c, np.mean(s_), np.mean(a_), np.mean(dis_), np.mean(o_), np.mean(dir_), theta_) #aspect ratio\n#             ars = calculate_eccentricity_fx(sa, sb, sc, np.mean(s_), np.mean(a_), np.mean(dis_), np.mean(o_), np.mean(dir_), theta_)\n#             ara = calculate_eccentricity_fx(aa, ab, ac, np.mean(s_), np.mean(a_), np.mean(dis_), np.mean(o_), np.mean(dir_), theta_)\n#             arxy = calculate_eccentricity_fx(a, b, c, torch.mean(s_), torch.mean(a_), torch.mean(dis_), torch.mean(o_), torch.mean(dir_), theta_) #aspect ratio\n#             ars = calculate_eccentricity_fx(sa, sb, sc, torch.mean(s_), torch.mean(a_), torch.mean(dis_), torch.mean(o_), torch.mean(dir_), theta_)\n#             ara = calculate_eccentricity_fx(aa, ab, ac, torch.mean(s_), torch.mean(a_), torch.mean(dis_), torch.mean(o_), torch.mean(dir_), theta_)\n\n\n            \n            if player_data['club'].iloc[0] == offensiveTeamAbbr:\n#                 no_transforms[gameId][playId]['offense'][nflId] = {'eccentricity': eccentricity, 'disp':disp, 'theta': theta_, 'cuv':curvature, 'cuvx': avg_cuvx, 'cuvy': avg_cuvy, 'disc':discriminant, 'major':al, 'minor':bl, 'arxy':arxy, 'ars':ars, 'ara': ara, 'theta_s': theta_s, 'theta_a':theta_a, 'xl':xl, 'yl':yl, 'x_mean':x_mean, 'y_mean':y_mean, 'gameid': group_data['meta_data']['gameId'], 'playid': group_data['meta_data']['playId'], 'a'=a,'b'= b,'c'=c,'d'=d,'e'=e,'f'=f, 'sa'=sa, 'sb'=sb, 'sc'=sc, s'sd'=d, 'se'=se, 'sf'sf, 'aa'=aa, 'ab'=ab, 'ac'= ac, 'ad'=ad, 'ae'=ae, 'af'=af}\n#                 no_transforms[gameId][playId]['offense'][nflId] = {'a'=a,'b'= b,'c'=c,'d'=d,'e'=e,'f'=f, 'sa'=sa, 'sb'=sb, 'sc'=sc, s'sd'=d, 'se'=se, 'sf'sf, 'aa'=aa, 'ab'=ab, 'ac'= ac, 'ad'=ad, 'ae'=ae, 'af'=af}  \n                no_transforms[gameId][playId]['offense'][nflId] = {'disp':disp, 'a':a,'b': b,'c': c,'d': d,'e': e,'f': f, 'sa': sa, 'sb': sb, 'sc':sc, 'sd': sd, 'se':se, 'sf': sf, 'aa': aa, 'ab': ab, 'ac': ac, 'ad': ad, 'ae': ae, 'af': af, 'xl':xl, 'yl':yl, 'x_mean':x_mean, 'y_mean':y_mean, 'gameid': group_data['meta_data']['gameId'], 'playid': group_data['meta_data']['playId']} #, 'last_event'=last_event}  \n                    \n            elif player_data['club'].iloc[0] == defensiveTeamAbbr:\n#                 no_transforms[gameId][playId]['defense'][nflId] = {'eccentricity': eccentricity, 'disp':disp, 'theta': theta_, 'cuv':curvature,  'cuvx': avg_cuvx, 'cuvy': avg_cuvy, 'disc':discriminant, 'major':al, 'minor':bl, 'arxy':arxy, 'ars':ars, 'ara': ara, 'theta_s': theta_s, 'theta_a':theta_a, 'xl':xl, 'yl':yl, 'x_mean':x_mean, 'y_mean':y_mean, 'gameid': group_data['meta_data']['gameId'], 'playid': group_data['meta_data']['playId']}\n                no_transforms[gameId][playId]['defense'][nflId] = {'disp':disp, 'a':a,'b': b,'c': c,'d': d,'e': e,'f': f, 'sa': sa, 'sb': sb, 'sc':sc, 'sd': sd, 'se':se, 'sf': sf, 'aa': aa, 'ab': ab, 'ac': ac, 'ad': ad, 'ae': ae, 'af': af, 'xl':xl, 'yl':yl, 'x_mean':x_mean, 'y_mean':y_mean, 'gameid': group_data['meta_data']['gameId'], 'playid': group_data['meta_data']['playId']} #, 'last_event'=last_event}\n                \n        else:\n            play_count_without_snap_event += 1\n            events_without_snap[(gameId, playId)] = player_data['event'].unique()  # Store unique events\n\n# Final summary\nprint(f\"Total plays processed: {len(tracking_data_dict_play_subset)}\")\nprint(f\"Plays with 'ball_snap' or 'snap_direct' event: {play_count_with_snap_event}\")\nprint(f\"Plays without 'ball_snap' or 'snap_direct' event: {play_count_without_snap_event}\")\n\n\n#  12%|█▏        | 402/3347 [14:22<1:43:40,  2.11s/it]\n#   0%|          | 13/3362 [01:03<4:29:05,  4.82s/it] #gpu\n\n\n\n\n\n\n\n\n# import torch\n\n# Save the no_transforms dictionary to a file\n# torch.save(no_transforms, 'no_transforms.pth')\n# torch.save(no_transforms, 'no_transforms[6-8].pth')\n# torch.save(no_transforms, 'temp_full_.pth')\n#  41%|████      | 1384/3362 [28:46<41:07,  1.25s/it] \n# 96.65 mb\n# 250 mb 2w -> 1.3  gb for 9w  in gen\n\n# # Load the dictionary from the file\n# loaded_no_transforms = torch.load('no_transforms.pth')\n\n# print(loaded_no_transforms)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"theta_ = torch.arctan2(torch.tensor(b, device=device), torch.tensor(a - c, device=device)) / 2\ntheta_s = torch.arctan2(torch.tensor(sb, device=device), torch.tensor(sa - sc, device=device)) / 2\ntheta_a = torch.arctan2(torch.tensor(ab, device=device), torch.tensor(aa - ac, device=device)) / 2\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:09:00.815248Z","iopub.execute_input":"2025-01-12T16:09:00.815624Z","iopub.status.idle":"2025-01-12T16:09:00.822319Z","shell.execute_reply.started":"2025-01-12T16:09:00.815594Z","shell.execute_reply":"2025-01-12T16:09:00.821211Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"\ns_ = torch.tensor([0.,0.,0.])\na_ = torch.tensor([0.,0.,0.])\no_ = torch.tensor([0.,0.,0.])\ndir_ = torch.tensor([0.,0.,0.])\n# theta_ = torch.tensor([0.,0.,0.])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T16:09:01.642719Z","iopub.execute_input":"2025-01-12T16:09:01.643067Z","iopub.status.idle":"2025-01-12T16:09:01.648595Z","shell.execute_reply.started":"2025-01-12T16:09:01.643041Z","shell.execute_reply":"2025-01-12T16:09:01.647400Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# import tqdm as twdm\nfrom tqdm import tqdm\n\ndata_list = []\n\nfor gameId in tqdm(no_transforms, desc=\"Games\", unit=\"game\"):\n#     print('YG')\n# for gameId in no_transforms:\n    for playId in no_transforms[gameId]: #2022101607 1127\n\n#         print('YP')\n#         for team_type in ['home', 'away', 'offense', 'defense']:\n        for team_type in ['offense', 'defense']:\n#             print('OD')\n            for nflId, player_data in no_transforms[gameId][playId][team_type].items():\n#                 print(nflId)\n#                 if 'eccentricity' in player_data:\n\n                a = player_data['a']\n                b = player_data['b']\n                c = player_data['c']\n                d = player_data['d']\n                e = player_data['e']\n                f = player_data['f']\n\n                theta_ = torch.arctan2(torch.tensor(player_data['b'], device=device), torch.tensor(player_data['a'] - player_data['c'], device=device)) / 2\n                # print(theta_)\n                theta_s = torch.arctan2(torch.tensor(player_data['sb'], device=device), torch.tensor(player_data['sa'] - player_data['sc'], device=device)) / 2\n                theta_a = torch.arctan2(torch.tensor(player_data['ab'], device=device), torch.tensor(player_data['aa'] - player_data['ac'], device=device)) / 2\n\n                eccentricity = calculate_eccentricity(player_data['a'], player_data['b'], player_data['c'], torch.mean(s_), torch.mean(a_), torch.mean(player_data['disp']), torch.mean(o_), torch.mean(dir_), theta_)\n                eccentricity_s = calculate_eccentricity(player_data['sa'], player_data['sb'], player_data['sc'], torch.mean(s_), torch.mean(a_), torch.mean(player_data['disp']), torch.mean(o_), torch.mean(dir_), theta_)\n                eccentricity_a = calculate_eccentricity(player_data['aa'], player_data['ab'], player_data['ac'], torch.mean(s_), torch.mean(a_), torch.mean(player_data['disp']), torch.mean(o_), torch.mean(dir_), theta_)\n                # theta_ = torch.arctan2(torch.tensor(player_data['b'], device=device), torch.tensor(player_data['a'] - player_data['c'], device=device)) / 2\n                # print(theta_)\n                # theta_s = torch.arctan2(torch.tensor(player_data['sb'], device=device), torch.tensor(player_data['sa'] - player_data['sc'], device=device)) / 2\n                # theta_a = torch.arctan2(torch.tensor(player_data['ab'], device=device), torch.tensor(player_data['aa'] - player_data['ac'], device=device)) / 2\n\n\n                eccentricity_extended = calculate_conic_eccentricity_extended(player_data['a'], player_data['b'], player_data['c'], player_data['d'], player_data['e'], player_data['f'])#calculate_eccentricity_extended\n                eccentricity_s_extended = calculate_conic_eccentricity_extended(player_data['sa'], player_data['sb'], player_data['sc'], player_data['sd'], player_data['se'], player_data['sf'])#calculate_eccentricity_extended\n                eccentricity_a_extended = calculate_conic_eccentricity_extended(player_data['aa'], player_data['ab'], player_data['ac'], player_data['ad'], player_data['af'], player_data['af']) #calculate_eccentricity_extended\n\n                ### XYZ CUVS TODO CL\n\n                \n                disp = player_data['disp']\n\n\n                arxy = calculate_eccentricity_fx(player_data['a'], player_data['b'], player_data['c'], torch.mean(s_), torch.mean(a_), torch.mean(disp), torch.mean(o_), torch.mean(dir_), theta_)\n                ars = calculate_eccentricity_fx(player_data['sa'], player_data['sb'], player_data['sc'], torch.mean(s_), torch.mean(a_), torch.mean(disp), torch.mean(o_), torch.mean(dir_), theta_s)\n                ara = calculate_eccentricity_fx(player_data['aa'], player_data['ab'], player_data['ac'], torch.mean(s_), torch.mean(a_), torch.mean(disp), torch.mean(o_), torch.mean(dir_), theta_a)\n\n\n                \n                try:\n                    route_ran = player_play.loc[(player_play['gameId'] == gameId) &\n                                                (player_play['playId'] == playId) &\n                                                (player_play['nflId'] == nflId), 'routeRan'].values[0]\n\n                    hadRushAttempt_ = player_play.loc[(player_play['gameId'] == gameId) &\n                                                (player_play['playId'] == playId) &\n                                                (player_play['nflId'] == nflId), 'hadRushAttempt'].values[0]\n                    rushingYards_ = player_play.loc[(player_play['gameId'] == gameId) &\n                                                (player_play['playId'] == playId) &\n                                                (player_play['nflId'] == nflId), 'rushingYards'].values[0]\n\n                    pos = players.loc[players['nflId'] == nflId, 'position'].values[0] #, # cant speak why becomes lal on coment\n                    \n                    # eccentricity = calculate_eccentricity(player_data['a'], player_data['b'], player_data['c'], torch.mean(s_), torch.mean(a_), torch.mean(player_data['disp']), torch.mean(o_), torch.mean(dir_), theta_)\n                    # eccentricity_s = calculate_eccentricity(player_data['sa'], player_data['sb'], player_data['sc'], torch.mean(s_), torch.mean(a_), torch.mean(player_data['disp']), torch.mean(o_), torch.mean(dir_), theta_)\n                    # eccentricity_a = calculate_eccentricity(player_data['aa'], player_data['ab'], player_data['ac'], torch.mean(s_), torch.mean(a_), torch.mean(player_data['disp']), torch.mean(o_), torch.mean(dir_), theta_)\n                    # theta_ = torch.arctan2(torch.tensor(player_data['b'], device=device), torch.tensor(player_data['a'] - player_data['c'], device=device)) / 2\n                    # theta_s = torch.arctan2(torch.tensor(player_data['sb'], device=device), torch.tensor(player_data['sa'] - player_data['sc'], device=device)) / 2\n                    # theta_a = torch.arctan2(torch.tensor(player_data['ab'], device=device), torch.tensor(player_data['aa'] - player_data['ac'], device=device)) / 2\n       #week quarter\n                    \n                    w = games.loc[games['gameId'] == gameId, 'week'].values[0]#,\n                    \n                    q = plays.loc[(plays['gameId'] == gameId) &\n                                                (plays['playId'] == playId), 'quarter'].values[0]#,\n                    \n                    d = plays.loc[(plays['gameId'] == gameId) &\n                                                (plays['playId'] == playId), 'down'].values[0]\n\n#                     eccentricity\n                    # arxy = calculate_eccentricity_fx(player_data['a'], player_data['b'], player_data['c'], torch.mean(s_), torch.mean(a_), torch.mean(disp), torch.mean(o_), torch.mean(dir_), theta_)\n                    # ars = calculate_eccentricity_fx(player_data['sa'], player_data['sb'], player_data['sc'], torch.mean(s_), torch.mean(a_), torch.mean(disp), torch.mean(o_), torch.mean(dir_), theta_s)\n                    # ara = calculate_eccentricity_fx(player_data['aa'], player_data['ab'], player_data['ac'], torch.mean(s_), torch.mean(a_), torch.mean(disp), torch.mean(o_), torch.mean(dir_), theta_a)\n            \n                except IndexError:\n                    print(gameId, playId)\n                    route_ran = None  # In case routeRan is missing\n\n                    hadRushAttempt_ = None\n                    rushingYards_ = None\n\n                    pos = None\n                    \n                    w = None\n                    q = None\n                    d = None\n                    # arxy = None\n                    # ars = None\n                    # ara = None\n\n\n                    # eccentricity = None\n                    # eccentricity_s = None\n                    # eccentricity_a = None\n                    # theta_ = None\n                    # theta_s = None\n                    # theta_a = None\n\n\n                # eccentricity = calculate_eccentricity(player_data['a'], player_data['b'], player_data['c'], torch.mean(s_), torch.mean(a_), torch.mean(player_data['disp']), torch.mean(o_), torch.mean(dir_), theta_)\n                # eccentricity_s = calculate_eccentricity(player_data['sa'], player_data['sb'], player_data['sc'], torch.mean(s_), torch.mean(a_), torch.mean(player_data['disp']), torch.mean(o_), torch.mean(dir_), theta_)\n                # eccentricity_a = calculate_eccentricity(player_data['aa'], player_data['ab'], player_data['ac'], torch.mean(s_), torch.mean(a_), torch.mean(player_data['disp']), torch.mean(o_), torch.mean(dir_), theta_)\n                # theta_ = torch.arctan2(torch.tensor(player_data['b'], device=device), torch.tensor(player_data['a'] - player_data['c'], device=device)) / 2\n                # theta_s = torch.arctan2(torch.tensor(player_data['sb'], device=device), torch.tensor(player_data['sa'] - player_data['sc'], device=device)) / 2\n                # theta_a = torch.arctan2(torch.tensor(player_data['ab'], device=device), torch.tensor(player_data['aa'] - player_data['ac'], device=device)) / 2\n\n        \n                data_list.append({\n                    'gameId': gameId,\n                    'playId': playId,\n                    'nflId': nflId,\n\n#                     'eccentricity': player_data['eccentricity'],\n                    'routeRan': route_ran,\n                    'rushingYards': rushingYards_,\n\n                    'hadRushAttempt': hadRushAttempt_,\n                    \n#                         'dis': player_data['dis'].mean()\n                    'disp': player_data['disp'], #,\n                    'week': w,\n                    'quarter': q,\n                    'down' : d,\n                    'arxy': arxy,\n                    'ars': ars,\n                    'ara': ara,\n                    'pos' : pos,\n\n                    'eccentricity' : eccentricity,\n                    'eccentricity_s' : eccentricity_s,\n                    'eccentricity_a' : eccentricity_a,\n                    'theta_' : theta_,\n                    'theta_s' : theta_s,\n                    'theta_a' : theta_a,\n\n\n                    'eccentricity_extended' : eccentricity_extended,\n                    'eccentricity_extended_s' : eccentricity_s_extended,\n                    'eccentricity_extended_a' : eccentricity_a_extended,\n\n\n                    'a' : a,\n                    'b' : b,\n                    'c' : c,\n                    'd' : d,\n                    'e' : e,\n                    'f' : f\n                    # CAN CUVS\n                    ## add names\n                    \n#                         'quarter' : \n #                     #'theta': player_data['theta']\n#                     'theta': np.degrees(player_data['theta']),\n#                     'theta_abs': np.abs(np.degrees(player_data['theta'])),\n#                     'curvature' : player_data['cuv'],\n#                     'curvaturex' : player_data['cuvx'],\n#                     'curvaturey' : player_data['cuvy'],\n#                     'curvaturexabs' : np.abs(player_data['cuvx']),\n#                     'discriminant' : player_data['disc'],\n\n\n#                     #'rushingYards' : rushingYards_, 'disp':disp, 'week': w, 'quarter':q, 'theta': theta_, 'cuv':curvature, 'cuvx': avg_cuvx, 'cuvy': avg_cuvy, 'disc':discriminant, \n#                     'major':player_data['major'], 'minor':player_data['minor'], 'arxy':player_data['arxy'], 'ars':player_data['ars'], 'ara': player_data['ara'], 'theta_s': np.degrees(player_data['theta_s']), 'theta_a':np.degrees(player_data['theta_a']), 'xl':player_data['xl'], 'yl':player_data['yl'], 'x_mean':player_data['x_mean'], 'y_mean':player_data['y_mean']\n\n#                         'dir'\n                })\n                #wkk2 order of [''] pairing, : annotation  'major' as key rather no quotes\n\n\n\n# torch.save(no_transforms, 'no_transforms.pth')\n\n\n\n# Create a DataFrame from the list\neccentricity_df = pd.DataFrame(data_list)\ntorch.save(eccentricity_df, 'eccentricity_df.pth')\n\neccentricity_df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom tqdm import tqdm\n\n# Load the eccentricity_df if not already loaded\n# eccentricity_df = torch.load('/kaggle/working/eccentricity_df.pth')\n\n# Ensure eccentricity_df is a DataFrame (if it isn't already)\nif not isinstance(eccentricity_df, pd.DataFrame):\n    eccentricity_df = pd.DataFrame(eccentricity_df)\n\n# Assuming player_play is another DataFrame already loaded, with relevant data\n# Use tqdm to add a progress bar\nfor idx, row in tqdm(eccentricity_df.iterrows(), total=eccentricity_df.shape[0], desc=\"Updating passResult\"):\n    gameId = row['gameId']\n    playId = row['playId']\n    nflId = row['nflId']\n    \n    try:\n        # Extract the 'passResult' for the given gameId, playId, and nflId\n        pass_result = player_play.loc[\n            (player_play['gameId'] == gameId) &\n            (player_play['playId'] == playId) &\n            (player_play['nflId'] == nflId), 'rushingYards'\n        ].values[0]  # Assuming 'passResult' exists in player_play\n\n        pass_result = player_play.loc[\n            (player_play['gameId'] == gameId) &\n            (player_play['playId'] == playId) &\n            (player_play['nflId'] == nflId), 'passingYards'\n        ].values[0]  # Assuming 'passResult' exists in player_play\n\n        \n        # Add 'passResult' to the eccentricity_df\n        eccentricity_df.at[idx, 'rushingYards'] = pass_result\n        eccentricity_df.at[idx, 'passingYards'] = pass_result\n    except IndexError:\n        # Handle case where no matching 'passResult' is found\n        eccentricity_df.at[idx, 'rushingYards'] = None\n        eccentricity_df.at[idx, 'passingYards'] = None\n        \n# Optionally, save the updated dataframe\n# torch.save(eccentricity_df, '/kaggle/working/eccentricity_df_with_passResult.pth')\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom tqdm import tqdm\n\n# Load the eccentricity_df if not already loaded\n# eccentricity_df = torch.load('/kaggle/working/eccentricity_df.pth')\n\n# Ensure eccentricity_df is a DataFrame (if it isn't already)\nif not isinstance(eccentricity_df2, pd.DataFrame):\n    eccentricity_df2 = pd.DataFrame(eccentricity_df2)\n\n# Assuming player_play is another DataFrame already loaded, with relevant data\n# Use tqdm to add a progress bar\nfor idx, row in tqdm(eccentricity_df2.iterrows(), total=eccentricity_df2.shape[0], desc=\"Updating passResult\"):\n    gameId = row['gameId']\n    playId = row['playId']\n    nflId = row['nflId']\n    \n    try:\n        # Extract the 'passResult' for the given gameId, playId, and nflId\n        wasRunningRoute_result = player_play.loc[\n            (player_play['gameId'] == gameId) &\n            (player_play['playId'] == playId) &\n            (player_play['nflId'] == nflId), 'wasRunningRoute'\n        ].values[0]  # Assuming 'passResult' exists in player_play\n        \n        # Add 'passResult' to the eccentricity_df\n        eccentricity_df2.at[idx, 'wasRunningRoute'] = wasRunningRoute_result\n    except IndexError:\n        # Handle case where no matching 'passResult' is found\n        eccentricity_df2.at[idx, 'wasRunningRoute'] = None\n\n        \n# Optionally, save the updated dataframe\n# torch.save(eccentricity_df, '/kaggle/working/eccentricity_df_with_passResult.pth')\ntorch.save(eccentricity_df2, '/kaggle/working/eccentricity_df3.pth')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom tqdm import tqdm\n\n# Load the eccentricity_df if not already loaded\n# eccentricity_df = torch.load('/kaggle/working/eccentricity_df.pth')\n\n# Ensure eccentricity_df is a DataFrame (if it isn't already)\nif not isinstance(eccentricity_df, pd.DataFrame):\n    eccentricity_df = pd.DataFrame(eccentricity_df)\n\n# Assuming player_play is another DataFrame already loaded, with relevant data\n# Use tqdm to add a progress bar\nfor idx, row in tqdm(eccentricity_df.iterrows(), total=eccentricity_df.shape[0], desc=\"Updating passResult\"):\n    gameId = row['gameId']\n    playId = row['playId']\n    nflId = row['nflId']\n    \n    try:\n        # Extract the 'passResult' for the given gameId, playId, and nflId\n        wasRunningRoute_result = player_play.loc[\n            (player_play['gameId'] == gameId) &\n            (player_play['playId'] == playId) &\n            (player_play['nflId'] == nflId), 'wasRunningRoute'\n        ].values[0]  # Assuming 'passResult' exists in player_play\n        \n        # Add 'passResult' to the eccentricity_df\n        eccentricity_df.at[idx, 'wasRunningRoute'] = wasRunningRoute_result\n    except IndexError:\n        # Handle case where no matching 'passResult' is found\n        eccentricity_df.at[idx, 'wasRunningRoute'] = None\n\n        \n# Optionally, save the updated dataframe\n# torch.save(eccentricity_df, '/kaggle/working/eccentricity_df_with_passResult.pth')\ntorch.save(eccentricity_df, '/kaggle/working/eccentricity_df3.pth')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}